{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client = chromadb.PersistentClient() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_or_create_collection(name=\"drd2\") #persistent collection had been previously created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d09cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Load collected papers\n",
    "with open('processed_chunks.json', 'r') as f:\n",
    "    chunks = json.load(f)\n",
    "metadatas = [{\"title\": chunk[\"title\"], \"first_author\": chunk[\"first_author\"], \"date_published\": chunk[\"date_published\"]} for chunk in chunks] \n",
    "ids = [chunk[\"chunk_id\"] for chunk in chunks]\n",
    "texts = [chunk[\"text\"] for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22bd0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.upsert(\n",
    "    ids=ids,\n",
    "    metadatas=metadatas,\n",
    "    documents=texts,\n",
    ") #takes about 7 minutes to update collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"<GEMINI_API_KEY>\"\")\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-lite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8059311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve relevant chunks from Chroma, format them, and pass them to Gemini\n",
    "def RAG(query: str, n_results = 8) -> str:\n",
    "    retrieved_chunks = collection.query(\n",
    "        query_texts=query,\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return_to_gemini = [f\"Retrieved from \\\"{retrieved_chunks['metadatas'][0][i]['title']},\\\" {retrieved_chunks['metadatas'][0][i]['date_published']}, by {retrieved_chunks['metadatas'][0][i]['first_author']} et al.: {retrieved_chunks['documents'][0][i]}\" for i in range(n_results)]\n",
    "    response = generate_answer_with_context(query, retrieved_chunks=return_to_gemini)\n",
    "    return response\n",
    "    \n",
    "\n",
    "def generate_answer_with_context(query: str, retrieved_chunks: list[str]) -> str:\n",
    "    \n",
    "    context = \"\\n\\n\".join(retrieved_chunks)  # Combine chunks into a single context string\n",
    "\n",
    "    prompt = f\"\"\"You are a RAG system designed to provide useful genetic and genomic information for clinicians to aid their work\n",
    "    diagnosis, etiology, treatment and anything else they need.\n",
    "    A clinician has entered the query below and the context contains relevant chunks retrieved from a database of research on the DRD2 gene. \n",
    "    Use as many or as few of the sources as you need to answer the question accurately and concisely. You may also use existing knowledge from your training base.\n",
    "    Please cite studies if applicable. If the provided context does not have information to answer the question, please state as much.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {query}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return str(response.text)\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea95cdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"Are there known drug-drug interactions that specifically impact medications targeting the DRD2 receptor?\"\n",
    "print(RAG(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
